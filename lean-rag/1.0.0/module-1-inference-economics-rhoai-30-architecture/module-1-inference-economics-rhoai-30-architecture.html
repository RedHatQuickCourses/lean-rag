<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Module 1: Inference Economics &amp; RHOAI 3.0 Architecture :: Lean RAG Accelerator QuickStart Training</title>
    <link rel="prev" href="../LABENV/index.html">
    <link rel="next" href="analysis-of-the-impossible-trinity-in-llm-deployments-balancing-accuracy-latency-and-cost.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Lean RAG Accelerator QuickStart Training</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="lean-rag" data-version="1.0.0">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Lean RAG Accelerator QuickStart Training</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="module-1-inference-economics-rhoai-30-architecture.html">Module 1: Inference Economics &amp; RHOAI 3.0 Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="analysis-of-the-impossible-trinity-in-llm-deployments-balancing-accuracy-latency-and-cost.html">Analysis of the "Impossible Trinity" in LLM Deployments: Balancing Accuracy, Latency, and Cost</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="identifying-critical-gpu-underutilization-and-the-role-of-memory-management-in-inference-costs.html">Identifying "Critical GPU Underutilization" and the Role of Memory Management in Inference Costs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="overview-of-the-red-hat-ai-30-ai-factory-approach-for-industrialized-model-serving.html">Overview of the Red Hat OpenShift AI 3.0 "AI Factory" Approach for Industrialized Model Serving</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="mapping-the-rhoai-30-inference-stack-vllm-llm-d-and-kserve-integration.html">Mapping the RHOAI 3.0 inference stack: vLLM, llm-d, and KServe integration</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/module-2-model-optimization-with-llm-compressor.html">Module 2: Model Optimization with LLM Compressor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/techniques-for-model-compression-quantization-fp8-int8-and-sparsity.html">Techniques for Model Compression: Quantization (FP8, INT8) and Sparsity</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/using-llm-compressor-to-create-optimized-modelcars-containerized-models.html">Using LLM Compressor to Create Optimized Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/implementing-quantization-recipes-eg-smoothquant-gptq-to-reduce-gpu-memory-footprint.html">Implementing quantization recipes (e.g., SmoothQuant, GPTQ) to reduce GPU memory footprint</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/accessing-validated-pre-optimized-models-eg-lean-llama-from-the-red-hat-model-catalog.html">Accessing Validated, Pre-optimized Models from the Red Hat Model Catalog</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/module-3-high-performance-serving-with-vllm-llm-d.html">Module 3: High-Performance Serving with vLLM &amp; llm-d</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/configuring-vllm-for-maximum-throughput-using-pagedattention-and-continuous-batching.html">Configuring vLLM for Maximum Throughput Using PagedAttention and Continuous Batching</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/tuning-vllm-engine-arguments---gpu-memory-utilization-and---max-num-seqs.html">tuning vLLM engine arguments: <code>--gpu-memory-utilization</code> and <code>--max-num-seqs</code></a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/deploying-distributed-inference-with-llm-d-to-separate-prefill-and-decode-phases-disaggregation.html">Deploying distributed inference with llm-d to separate prefill and decode phases (disaggregation)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/implementing-prefix-caching-to-reuse-key-value-kv-cache-for-rag-system-prompts.html">Implementing prefix caching to reuse Key-Value (KV) cache for RAG system prompts</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-4-standardized-rag-implementation/module-4-standardized-rag-implementation.html">Module 4: Standardized RAG Implementation</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/ingesting-and-chunking-unstructured-enterprise-data-pdfs-using-docling.html">Ingesting and Chunking Unstructured Enterprise Data using Docling</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/orchestrating-rag-workflows-using-the-llama-stack-api-for-standardized-response-generation-and-vector-io.html">Orchestrating RAG Workflows with the Llama Stack API</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/integrating-vector-databases-eg-milvus-chroma-via-llama-stack-providers.html">Integrating Vector Databases via Llama Stack Providers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/deploying-the-rag-application-stack-using-gitops-and-argocd-for-repeatability.html">deploying the RAG application stack using GitOps and ArgoCD for repeatability</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-5-validation-benchmarking/module-5-validation-benchmarking.html">Module 5: Validation &amp; Benchmarking</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/defining-service-level-objectives-slos-for-time-to-first-token-ttft-and-inter-token-latency-itl.html">Defining Service Level Objectives (SLOs) for Time To First Token (TTFT) and Inter-Token Latency (ITL)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/simulating-real-world-traffic-load-using-guidellm-to-validate-throughput-gains.html">Simulating real-world traffic load using GuideLLM to validate throughput gains</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/comparing-performance-metrics-throughput-vs-latency.html">Comparing performance metrics (throughput vs. latency</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Lean RAG Accelerator QuickStart Training</span>
    <span class="version">1.0.0</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Lean RAG Accelerator QuickStart Training</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.0.0</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Lean RAG Accelerator QuickStart Training</a></li>
    <li><a href="module-1-inference-economics-rhoai-30-architecture.html">Module 1: Inference Economics &amp; RHOAI 3.0 Architecture</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Module 1: Inference Economics &amp; RHOAI 3.0 Architecture</h1>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a>Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This module establishes the foundation for understanding why optimization matters and how Red Hat OpenShift AI (RHOAI) 3.0 addresses the critical challenges of LLM inference economics. You&#8217;ll learn about the fundamental trade-offs in LLM deployments and how RHOAI 3.0&#8217;s AI Factory approach provides solutions.</p>
</div>
<div class="paragraph">
<p><strong>Key Learning Objectives:</strong>
- Understand the "Impossible Trinity" trade-offs (Accuracy, Latency, Cost)
- Identify GPU underutilization patterns and their cost impact
- Learn about RHOAI 3.0&#8217;s AI Factory approach
- Map the RHOAI 3.0 inference stack components</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_module_overview"><a class="anchor" href="#_module_overview"></a>Module Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Most GenAI deployments fail not because the model isn&#8217;t smart, but because it becomes too expensive to run at scale. This module explains why and introduces RHOAI 3.0&#8217;s solutions.</p>
</div>
<div class="sect2">
<h3 id="_the_problem"><a class="anchor" href="#_the_problem"></a>The Problem</h3>
<div class="ulist">
<ul>
<li>
<p><strong>&lt;40% GPU Utilization</strong>: Most deployments waste 60% of expensive GPU capacity</p>
</li>
<li>
<p><strong>Runaway Inference Economics</strong>: 95% of AI pilots fail due to cost</p>
</li>
<li>
<p><strong>Memory Bottlenecks</strong>: KV cache inefficiency prevents efficient batching</p>
</li>
<li>
<p><strong>Trade-off Decisions</strong>: Must balance accuracy, latency, and cost</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_the_solution_rhoai_3_0_ai_factory"><a class="anchor" href="#_the_solution_rhoai_3_0_ai_factory"></a>The Solution: RHOAI 3.0 AI Factory</h3>
<div class="paragraph">
<p>RHOAI 3.0&#8217;s AI Factory approach provides:
- <strong>Industrialized Model Serving</strong>: Standardized components and workflows
- <strong>Optimization Tools</strong>: LLM Compressor for model quantization
- <strong>High-Performance Inference</strong>: vLLM and llm-d for maximum throughput
- <strong>Standardized RAG</strong>: Llama Stack for consistent deployments</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_topics_covered"><a class="anchor" href="#_topics_covered"></a>Topics Covered</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_section_1_1_the_impossible_trinity"><a class="anchor" href="#_section_1_1_the_impossible_trinity"></a>Section 1.1: The Impossible Trinity</h3>
<div class="paragraph">
<p>Learn about the fundamental constraint in LLM deployments: you cannot simultaneously optimize accuracy, latency, and cost. This section covers:
- The three competing objectives
- Real-world trade-off scenarios
- Decision frameworks
- Optimization strategies</p>
</div>
<div class="paragraph">
<p><strong>Duration</strong>: 30-45 minutes</p>
</div>
</div>
<div class="sect2">
<h3 id="_section_1_2_gpu_underutilization_memory_management"><a class="anchor" href="#_section_1_2_gpu_underutilization_memory_management"></a>Section 1.2: GPU Underutilization &amp; Memory Management</h3>
<div class="paragraph">
<p>Understand why most deployments use &lt;40% of GPU capacity and how memory management impacts costs:
- KV cache bottleneck analysis
- Memory fragmentation problems
- Cost calculation examples
- Optimization techniques</p>
</div>
<div class="paragraph">
<p><strong>Duration</strong>: 45-60 minutes</p>
</div>
</div>
<div class="sect2">
<h3 id="_section_1_3_rhoai_3_0_ai_factory_approach"><a class="anchor" href="#_section_1_3_rhoai_3_0_ai_factory_approach"></a>Section 1.3: RHOAI 3.0 AI Factory Approach</h3>
<div class="paragraph">
<p>Explore Red Hat&#8217;s industrialized model serving methodology:
- AI Factory principles
- Standardized components
- Automated workflows
- Benefits over ad-hoc deployments</p>
</div>
<div class="paragraph">
<p><strong>Duration</strong>: 45-60 minutes</p>
</div>
</div>
<div class="sect2">
<h3 id="_section_1_4_rhoai_3_0_inference_stack"><a class="anchor" href="#_section_1_4_rhoai_3_0_inference_stack"></a>Section 1.4: RHOAI 3.0 Inference Stack</h3>
<div class="paragraph">
<p>Map the inference stack components:
- vLLM: High-performance inference engine
- llm-d: Cloud-native orchestrator
- KServe: Kubernetes-native serving framework
- Integration and data flow</p>
</div>
<div class="paragraph">
<p><strong>Duration</strong>: 60-75 minutes</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_prerequisites"><a class="anchor" href="#_prerequisites"></a>Prerequisites</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Before starting this module, ensure you have:
- Basic understanding of LLMs and inference
- Familiarity with Kubernetes concepts
- Access to RHOAI 3.0 documentation (for reference)</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_expected_outcomes"><a class="anchor" href="#_expected_outcomes"></a>Expected Outcomes</h2>
<div class="sectionbody">
<div class="paragraph">
<p>By the end of this module, you will be able to:
- Explain the Impossible Trinity trade-offs
- Calculate the cost of GPU underutilization
- Describe RHOAI 3.0&#8217;s AI Factory approach
- Map the inference stack components
- Make informed decisions about optimization strategies</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_module_structure"><a class="anchor" href="#_module_structure"></a>Module Structure</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This module follows a conceptual learning path:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Problem Understanding</strong>: Learn why optimization matters</p>
</li>
<li>
<p><strong>Solution Introduction</strong>: Understand RHOAI 3.0&#8217;s approach</p>
</li>
<li>
<p><strong>Architecture Mapping</strong>: Explore the inference stack</p>
</li>
<li>
<p><strong>Decision Framework</strong>: Apply concepts to real scenarios</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_next_steps"><a class="anchor" href="#_next_steps"></a>Next Steps</h2>
<div class="sectionbody">
<div class="paragraph">
<p>After completing this module:
- Proceed to Module 2 to learn about model optimization techniques
- Review the business value documentation for ROI analysis
- Explore the quickstart code to see concepts in practice</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_related_resources"><a class="anchor" href="#_related_resources"></a>Related Resources</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><a href="../../lean-rag-accelerator/docs/business-value-driver.md">Business Value Driver</a> - ROI and problem statement</p>
</li>
<li>
<p><a href="../../lean-rag-accelerator/docs/architecture.md">Architecture Documentation</a> - Technical architecture</p>
</li>
<li>
<p><a href="module-2-model-optimization-with-llm-compressor.adoc">Module 2: Model Optimization</a> - Next module</p>
</li>
</ul>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="../LABENV/index.html">Lab Environment</a></span>
  <span class="next"><a href="analysis-of-the-impossible-trinity-in-llm-deployments-balancing-accuracy-latency-and-cost.html">Analysis of the "Impossible Trinity" in LLM Deployments: Balancing Accuracy, Latency, and Cost</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
