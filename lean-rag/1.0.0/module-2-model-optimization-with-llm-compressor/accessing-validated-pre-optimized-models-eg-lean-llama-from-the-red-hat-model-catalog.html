<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Accessing validated, pre-optimized models (e.g., Lean Llama) from the Red Hat Model Catalog :: Lean RAG Accelerator QuickStart Training</title>
    <link rel="prev" href="implementing-quantization-recipes-eg-smoothquant-gptq-to-reduce-gpu-memory-footprint.html">
    <link rel="next" href="../module-3-high-performance-serving-with-vllm-llm-d/module-3-high-performance-serving-with-vllm-llm-d.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Lean RAG Accelerator QuickStart Training</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="lean-rag" data-version="1.0.0">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Lean RAG Accelerator QuickStart Training</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/module-1-inference-economics-rhoai-30-architecture.html">Module 1: Inference Economics &amp; RHOAI 3.0 Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/analysis-of-the-impossible-trinity-in-llm-deployments-balancing-accuracy-latency-and-cost.html">Analysis of the "Impossible Trinity" in LLM deployments: balancing Accuracy, Latency, and Cost</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/identifying-critical-gpu-underutilization-and-the-role-of-memory-management-in-inference-costs.html">Identifying "Critical GPU Underutilization" and the role of memory management in inference costs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/overview-of-the-red-hat-ai-30-ai-factory-approach-for-industrialized-model-serving.html">Overview of the Red Hat AI 3.0 "AI Factory" approach for industrialized model serving</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/mapping-the-rhoai-30-inference-stack-vllm-llm-d-and-kserve-integration.html">Mapping the RHOAI 3.0 inference stack: vLLM, llm-d, and KServe integration</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="module-2-model-optimization-with-llm-compressor.html">Module 2: Model Optimization with LLM Compressor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="techniques-for-model-compression-quantization-fp8-int8-and-sparsity.html">Techniques for model compression: Quantization (FP8, INT8) and Sparsity</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="using-llm-compressor-to-create-optimized-modelcars-containerized-models.html">Using LLM Compressor to create optimized "ModelCars" (containerized models)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="implementing-quantization-recipes-eg-smoothquant-gptq-to-reduce-gpu-memory-footprint.html">Implementing quantization recipes (e.g., SmoothQuant, GPTQ) to reduce GPU memory footprint</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="accessing-validated-pre-optimized-models-eg-lean-llama-from-the-red-hat-model-catalog.html">Accessing validated, pre-optimized models (e.g., Lean Llama) from the Red Hat Model Catalog</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/module-3-high-performance-serving-with-vllm-llm-d.html">Module 3: High-Performance Serving with vLLM &amp; llm-d</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/configuring-vllm-for-maximum-throughput-using-pagedattention-and-continuous-batching.html">configuring vLLM for maximum throughput using PagedAttention and Continuous Batching</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/tuning-vllm-engine-arguments---gpu-memory-utilization-and---max-num-seqs.html">tuning vLLM engine arguments: <code>--gpu-memory-utilization</code> and <code>--max-num-seqs</code></a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/deploying-distributed-inference-with-llm-d-to-separate-prefill-and-decode-phases-disaggregation.html">Deploying distributed inference with llm-d to separate prefill and decode phases (disaggregation)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/implementing-prefix-caching-to-reuse-key-value-kv-cache-for-rag-system-prompts.html">Implementing prefix caching to reuse Key-Value (KV) cache for RAG system prompts</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-4-standardized-rag-implementation/module-4-standardized-rag-implementation.html">Module 4: Standardized RAG Implementation</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/ingesting-and-chunking-unstructured-enterprise-data-pdfs-using-docling.html">Ingesting and chunking unstructured enterprise data (PDFs) using Docling</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/orchestrating-rag-workflows-using-the-llama-stack-api-for-standardized-response-generation-and-vector-io.html">Orchestrating RAG workflows using the Llama Stack API for standardized "Response Generation" and "Vector IO"</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/integrating-vector-databases-eg-milvus-chroma-via-llama-stack-providers.html">Integrating vector databases (e.g., Milvus, Chroma) via Llama Stack providers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-4-standardized-rag-implementation/deploying-the-rag-application-stack-using-gitops-and-argocd-for-repeatability.html">deploying the RAG application stack using GitOps and ArgoCD for repeatability</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-5-validation-benchmarking/module-5-validation-benchmarking.html">Module 5: Validation &amp; Benchmarking</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/defining-service-level-objectives-slos-for-time-to-first-token-ttft-and-inter-token-latency-itl.html">Defining Service Level Objectives (SLOs) for Time To First Token (TTFT) and Inter-Token Latency (ITL)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/simulating-real-world-traffic-load-using-guidellm-to-validate-throughput-gains.html">Simulating real-world traffic load using GuideLLM to validate throughput gains</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/comparing-performance-metrics-throughput-vs-latency.html">Comparing performance metrics (throughput vs. latency</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Lean RAG Accelerator QuickStart Training</span>
    <span class="version">1.0.0</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Lean RAG Accelerator QuickStart Training</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.0.0</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Lean RAG Accelerator QuickStart Training</a></li>
    <li><a href="module-2-model-optimization-with-llm-compressor.html">Module 2: Model Optimization with LLM Compressor</a></li>
    <li><a href="accessing-validated-pre-optimized-models-eg-lean-llama-from-the-red-hat-model-catalog.html">Accessing validated, pre-optimized models (e.g., Lean Llama) from the Red Hat Model Catalog</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Accessing validated, pre-optimized models (e.g., Lean Llama) from the Red Hat Model Catalog</h1>
<div class="sect1">
<h2 id="_accessing_validated_pre_optimized_models_from_the_red_hat_model_catalog"><a class="anchor" href="#_accessing_validated_pre_optimized_models_from_the_red_hat_model_catalog"></a>Accessing Validated, Pre-optimized Models from the Red Hat Model Catalog</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this section, we will explore how to access validated, pre-optimized models from the Red Hat Model Catalog, specifically focusing on the Lean Llama model. These pre-optimized models are crucial for reducing GPU memory footprint and accelerating inference times.</p>
</div>
<div class="sect2">
<h3 id="_1_introduction_to_red_hat_model_catalog"><a class="anchor" href="#_1_introduction_to_red_hat_model_catalog"></a>1. Introduction to Red Hat Model Catalog</h3>
<div class="paragraph">
<p>The Red Hat Model Catalog is a centralized repository for pre-trained, optimized machine learning models. It simplifies the process of model deployment and management by providing a collection of models that have been thoroughly tested and optimized for performance.</p>
</div>
</div>
<div class="sect2">
<h3 id="_2_accessing_lean_llama_model"><a class="anchor" href="#_2_accessing_lean_llama_model"></a>2. Accessing Lean Llama Model</h3>
<div class="paragraph">
<p>Lean Llama is a pre-optimized model available in the Red Hat Model Catalog, designed for efficient inference. To access this model, follow these steps:</p>
</div>
<div class="sect3">
<h4 id="_2_1_navigate_to_the_red_hat_model_catalog"><a class="anchor" href="#_2_1_navigate_to_the_red_hat_model_catalog"></a>2.1. Navigate to the Red Hat Model Catalog</h4>
<div class="paragraph">
<p>Visit the Red Hat Model Catalog at [<a href="https://model-catalog.rh-ai.com" class="bare">https://model-catalog.rh-ai.com</a>](<a href="https://model-catalog.rh-ai.com" class="bare">https://model-catalog.rh-ai.com</a>).</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_2_search_for_lean_llama"><a class="anchor" href="#_2_2_search_for_lean_llama"></a>2.2. Search for Lean Llama</h4>
<div class="paragraph">
<p>Use the search bar or browse through the available models to find "Lean Llama". Click on the model to view its details.</p>
</div>
</div>
<div class="sect3">
<h4 id="_2_3_download_the_model"><a class="anchor" href="#_2_3_download_the_model"></a>2.3. Download the Model</h4>
<div class="paragraph">
<p>The Red Hat Model Catalog provides containerized models, making it easy to deploy them in various environments. Click on the "Download" button to get the Lean Llama model in a container format (e.g., Docker image).</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_3_using_llm_compressor_with_lean_llama"><a class="anchor" href="#_3_using_llm_compressor_with_lean_llama"></a>3. Using LLM Compressor with Lean Llama</h3>
<div class="paragraph">
<p>To further optimize the Lean Llama model for inference, you can use the LLM Compressor tool. This tool allows you to create optimized "ModelCars" (containerized models) with techniques like quantization and sparsity.</p>
</div>
<div class="sect3">
<h4 id="_3_1_quantization_recipes"><a class="anchor" href="#_3_1_quantization_recipes"></a>3.1. Quantization Recipes</h4>
<div class="paragraph">
<p>Quantization recipes, such as SmoothQuant and GPTQ, can be applied to reduce the GPU memory footprint. These recipes are available within the LLM Compressor tool.</p>
</div>
</div>
<div class="sect3">
<h4 id="_3_2_implementing_quantization"><a class="anchor" href="#_3_2_implementing_quantization"></a>3.2. Implementing Quantization</h4>
<div class="paragraph">
<p>Follow these steps to implement quantization using LLM Compressor:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Install LLM Compressor: Follow the installation instructions provided in the [LLM Compressor documentation](<a href="https://llm-compressor.readthedocs.io/" class="bare">https://llm-compressor.readthedocs.io/</a></p>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="implementing-quantization-recipes-eg-smoothquant-gptq-to-reduce-gpu-memory-footprint.html">Implementing quantization recipes (e.g., SmoothQuant, GPTQ) to reduce GPU memory footprint</a></span>
  <span class="next"><a href="../module-3-high-performance-serving-with-vllm-llm-d/module-3-high-performance-serving-with-vllm-llm-d.html">Module 3: High-Performance Serving with vLLM &amp; llm-d</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
