<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Ingesting and Chunking Unstructured Enterprise Data using Docling :: Lean RAG Accelerator QuickStart Training</title>
    <link rel="prev" href="module-4-standardized-rag-implementation.html">
    <link rel="next" href="orchestrating-rag-workflows-using-the-llama-stack-api-for-standardized-response-generation-and-vector-io.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Lean RAG Accelerator QuickStart Training</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/REPLACEREPONAME/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="lean-rag" data-version="1.0.0">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Lean RAG Accelerator QuickStart Training</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../LABENV/index.html">Lab Environment</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/module-1-inference-economics-rhoai-30-architecture.html">Module 1: Inference Economics &amp; RHOAI 3.0 Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/analysis-of-the-impossible-trinity-in-llm-deployments-balancing-accuracy-latency-and-cost.html">Analysis of the "Impossible Trinity" in LLM Deployments: Balancing Accuracy, Latency, and Cost</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/identifying-critical-gpu-underutilization-and-the-role-of-memory-management-in-inference-costs.html">Identifying "Critical GPU Underutilization" and the Role of Memory Management in Inference Costs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/overview-of-the-red-hat-ai-30-ai-factory-approach-for-industrialized-model-serving.html">Overview of the Red Hat OpenShift AI 3.0 "AI Factory" Approach for Industrialized Model Serving</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-1-inference-economics-rhoai-30-architecture/mapping-the-rhoai-30-inference-stack-vllm-llm-d-and-kserve-integration.html">Mapping the RHOAI 3.0 inference stack: vLLM, llm-d, and KServe integration</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/module-2-model-optimization-with-llm-compressor.html">Module 2: Model Optimization with LLM Compressor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/techniques-for-model-compression-quantization-fp8-int8-and-sparsity.html">Techniques for Model Compression: Quantization (FP8, INT8) and Sparsity</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/using-llm-compressor-to-create-optimized-modelcars-containerized-models.html">Using LLM Compressor to Create Optimized Models</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/implementing-quantization-recipes-eg-smoothquant-gptq-to-reduce-gpu-memory-footprint.html">Implementing quantization recipes (e.g., SmoothQuant, GPTQ) to reduce GPU memory footprint</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-2-model-optimization-with-llm-compressor/accessing-validated-pre-optimized-models-eg-lean-llama-from-the-red-hat-model-catalog.html">Accessing Validated, Pre-optimized Models from the Red Hat Model Catalog</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/module-3-high-performance-serving-with-vllm-llm-d.html">Module 3: High-Performance Serving with vLLM &amp; llm-d</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/configuring-vllm-for-maximum-throughput-using-pagedattention-and-continuous-batching.html">Configuring vLLM for Maximum Throughput Using PagedAttention and Continuous Batching</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/tuning-vllm-engine-arguments---gpu-memory-utilization-and---max-num-seqs.html">tuning vLLM engine arguments: <code>--gpu-memory-utilization</code> and <code>--max-num-seqs</code></a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/deploying-distributed-inference-with-llm-d-to-separate-prefill-and-decode-phases-disaggregation.html">Deploying distributed inference with llm-d to separate prefill and decode phases (disaggregation)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-3-high-performance-serving-with-vllm-llm-d/implementing-prefix-caching-to-reuse-key-value-kv-cache-for-rag-system-prompts.html">Implementing prefix caching to reuse Key-Value (KV) cache for RAG system prompts</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="module-4-standardized-rag-implementation.html">Module 4: Standardized RAG Implementation</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="ingesting-and-chunking-unstructured-enterprise-data-pdfs-using-docling.html">Ingesting and Chunking Unstructured Enterprise Data using Docling</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="orchestrating-rag-workflows-using-the-llama-stack-api-for-standardized-response-generation-and-vector-io.html">Orchestrating RAG Workflows with the Llama Stack API</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="integrating-vector-databases-eg-milvus-chroma-via-llama-stack-providers.html">Integrating Vector Databases via Llama Stack Providers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="deploying-the-rag-application-stack-using-gitops-and-argocd-for-repeatability.html">deploying the RAG application stack using GitOps and ArgoCD for repeatability</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../module-5-validation-benchmarking/module-5-validation-benchmarking.html">Module 5: Validation &amp; Benchmarking</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/defining-service-level-objectives-slos-for-time-to-first-token-ttft-and-inter-token-latency-itl.html">Defining Service Level Objectives (SLOs) for Time To First Token (TTFT) and Inter-Token Latency (ITL)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/simulating-real-world-traffic-load-using-guidellm-to-validate-throughput-gains.html">Simulating real-world traffic load using GuideLLM to validate throughput gains</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../module-5-validation-benchmarking/comparing-performance-metrics-throughput-vs-latency.html">Comparing performance metrics (throughput vs. latency</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../appendix/appendix.html">Appendix</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Lean RAG Accelerator QuickStart Training</span>
    <span class="version">1.0.0</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Lean RAG Accelerator QuickStart Training</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.0.0</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Lean RAG Accelerator QuickStart Training</a></li>
    <li><a href="module-4-standardized-rag-implementation.html">Module 4: Standardized RAG Implementation</a></li>
    <li><a href="ingesting-and-chunking-unstructured-enterprise-data-pdfs-using-docling.html">Ingesting and Chunking Unstructured Enterprise Data using Docling</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Ingesting and Chunking Unstructured Enterprise Data using Docling</h1>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a>Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p><strong>Docling</strong> is a Python library that transforms raw unstructured data (PDFs, images, audio files) into structured, machine-readable formats that RAG pipelines can consume. It&#8217;s used in end-to-end workflows for preparing documents for RAG systems.</p>
</div>
<div class="paragraph">
<p><strong>Key Capabilities:</strong>
- PDF text extraction with OCR
- Table extraction and formatting
- Image processing
- Structured output formats
- Metadata extraction</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_understanding_docling"><a class="anchor" href="#_understanding_docling"></a>Understanding Docling</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_what_is_docling"><a class="anchor" href="#_what_is_docling"></a>What is Docling?</h3>
<div class="paragraph">
<p>Docling is a Python library designed for enterprise document processing. It handles:
- <strong>PDF Processing</strong>: Extract text, tables, images from PDFs
- <strong>OCR</strong>: Optical Character Recognition for scanned documents
- <strong>Structured Output</strong>: Convert unstructured documents to structured formats
- <strong>Metadata Extraction</strong>: Extract titles, authors, dates, keywords</p>
</div>
</div>
<div class="sect2">
<h3 id="_why_use_docling_for_rag"><a class="anchor" href="#_why_use_docling_for_rag"></a>Why Use Docling for RAG?</h3>
<div class="paragraph">
<p><strong>Benefits:</strong>
- <strong>High Quality Extraction</strong>: Advanced OCR and table extraction
- <strong>Structured Format</strong>: Output ready for RAG ingestion
- <strong>Metadata Preservation</strong>: Maintains document structure and metadata
- <strong>Enterprise Ready</strong>: Handles complex enterprise documents</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_installing_docling"><a class="anchor" href="#_installing_docling"></a>Installing Docling</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_python_installation"><a class="anchor" href="#_python_installation"></a>Python Installation</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Install Docling via pip
pip install docling

# Or with specific dependencies
pip install docling[ocr]  # Includes OCR capabilities</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_system_dependencies"><a class="anchor" href="#_system_dependencies"></a>System Dependencies</h3>
<div class="paragraph">
<p><strong>For OCR functionality:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ubuntu/Debian
sudo apt-get install tesseract-ocr

# macOS
brew install tesseract

# RHEL/CentOS
sudo yum install tesseract</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_basic_docling_usage"><a class="anchor" href="#_basic_docling_usage"></a>Basic Docling Usage</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_processing_a_single_document"><a class="anchor" href="#_processing_a_single_document"></a>Processing a Single Document</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter

# Initialize converter
converter = DocumentConverter()

# Process a PDF
result = converter.convert("document.pdf")

# Access extracted content
text = result.document.export_to_text()
tables = result.document.export_to_tables()</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_processing_multiple_documents"><a class="anchor" href="#_processing_multiple_documents"></a>Processing Multiple Documents</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter
import os

converter = DocumentConverter()

# Process directory of PDFs
input_dir = "/path/to/pdfs"
output_dir = "/path/to/output"

for filename in os.listdir(input_dir):
    if filename.endswith(".pdf"):
        input_path = os.path.join(input_dir, filename)
        result = converter.convert(input_path)

        # Save processed document
        output_path = os.path.join(output_dir, f"{filename}.json")
        result.document.export_to_json(output_path)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_document_processing_configuration"><a class="anchor" href="#_document_processing_configuration"></a>Document Processing Configuration</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_rag_specific_configuration"><a class="anchor" href="#_rag_specific_configuration"></a>RAG-Specific Configuration</h3>
<div class="paragraph">
<p>For RAG (Retrieval-Augmented Generation) document processing, Docling provides specific configuration options that can be set during document upload in the Generative AI Playground or programmatically:</p>
</div>
<div class="sect3">
<h4 id="_maximum_chunk_length"><a class="anchor" href="#_maximum_chunk_length"></a>Maximum Chunk Length</h4>
<div class="paragraph">
<p><strong>Setting</strong>: Maximum chunk length (word count)</p>
</div>
<div class="paragraph">
<p><strong>Purpose</strong>: Sets the maximum word count for each text section ("chunk") created from uploaded files.</p>
</div>
<div class="paragraph">
<p><strong>Configuration:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Example: Configure chunk length (in words, not tokens)
chunk_length = 512  # words per chunk</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices:</strong>
- Typical range: 200-1000 words
- Balance between context preservation and retrieval precision
- Consider your embedding model&#8217;s context window</p>
</div>
</div>
<div class="sect3">
<h4 id="_chunk_overlap"><a class="anchor" href="#_chunk_overlap"></a>Chunk Overlap</h4>
<div class="paragraph">
<p><strong>Setting</strong>: Chunk overlap (word count)</p>
</div>
<div class="paragraph">
<p><strong>Purpose</strong>: Determines the number of words from the end of one chunk that are repeated at the start of the next chunk, helping maintain continuous context.</p>
</div>
<div class="paragraph">
<p><strong>Configuration:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Example: Configure chunk overlap
chunk_overlap = 50  # words to overlap between chunks</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Best Practices:</strong>
- Typical range: 10-20% of chunk length
- Prevents information loss at chunk boundaries
- Improves context continuity for retrieval</p>
</div>
</div>
<div class="sect3">
<h4 id="_delimiter"><a class="anchor" href="#_delimiter"></a>Delimiter</h4>
<div class="paragraph">
<p><strong>Setting</strong>: Delimiter character or string</p>
</div>
<div class="paragraph">
<p><strong>Purpose</strong>: Specifies a character or string that marks where a text chunk should end, ensuring boundaries align logically (e.g., separating by period or newline).</p>
</div>
<div class="paragraph">
<p><strong>Configuration:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Example: Configure delimiter
delimiter = "\n\n"  # Split on double newline (paragraphs)
# Or:
delimiter = "."  # Split on periods (sentences)
# Or:
delimiter = None  # Use default semantic chunking</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Options:</strong>
- <code>"\n\n"</code>: Paragraph boundaries
- <code>"."</code>: Sentence boundaries
- <code>None</code>: Semantic chunking (default)</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ocr_configuration"><a class="anchor" href="#_ocr_configuration"></a>OCR Configuration</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter
from docling.datamodel.pipeline_options import PdfPipelineOptions

# Configure OCR
pipeline_options = PdfPipelineOptions()
pipeline_options.do_ocr = True
pipeline_options.do_table_structure = True
pipeline_options.table_structure_options.do_cell_matching = True

converter = DocumentConverter(pipeline_options=pipeline_options)</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_table_extraction"><a class="anchor" href="#_table_extraction"></a>Table Extraction</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter
from docling.datamodel.pipeline_options import PdfPipelineOptions

# Enable table extraction
pipeline_options = PdfPipelineOptions()
pipeline_options.do_table_structure = True
pipeline_options.table_structure_options.format = "markdown"  # or "html", "csv"

converter = DocumentConverter(pipeline_options=pipeline_options)
result = converter.convert("document.pdf")

# Export tables
tables = result.document.export_to_tables()</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_complete_rag_configuration_example"><a class="anchor" href="#_complete_rag_configuration_example"></a>Complete RAG Configuration Example</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter
from docling.datamodel.pipeline_options import PdfPipelineOptions
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Configure Docling for RAG
pipeline_options = PdfPipelineOptions()
pipeline_options.do_ocr = True
pipeline_options.do_table_structure = True

converter = DocumentConverter(pipeline_options=pipeline_options)
result = converter.convert("document.pdf")
text = result.document.export_to_text()

# Configure chunking for RAG
# Note: Docling uses word count, but we convert to tokens for consistency
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,      # Approximate tokens (converted from words)
    chunk_overlap=50,    # Overlap in tokens
    length_function=len,
    separators=["\n\n", "\n", ". ", " ", ""]  # Delimiters
)

chunks = text_splitter.split_text(text)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_chunking_documents_for_rag"><a class="anchor" href="#_chunking_documents_for_rag"></a>Chunking Documents for RAG</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_basic_chunking"><a class="anchor" href="#_basic_chunking"></a>Basic Chunking</h3>
<div class="paragraph">
<p>After processing documents with Docling, you need to chunk them for RAG:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Process document
converter = DocumentConverter()
result = converter.convert("document.pdf")
text = result.document.export_to_text()

# Chunk the text
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,      # Tokens per chunk
    chunk_overlap=50,    # Overlap between chunks
    length_function=len,
)

chunks = text_splitter.split_text(text)</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_semantic_chunking"><a class="anchor" href="#_semantic_chunking"></a>Semantic Chunking</h3>
<div class="paragraph">
<p>For better RAG performance, use semantic chunking:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from langchain.text_splitter import SemanticChunker
from langchain.embeddings import HuggingFaceEmbeddings

# Initialize embeddings for semantic chunking
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

# Create semantic chunker
chunker = SemanticChunker(
    embeddings=embeddings,
    chunk_size=512,
    chunk_overlap=50
)

# Chunk document
chunks = chunker.create_documents([text])</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_preserving_metadata"><a class="anchor" href="#_preserving_metadata"></a>Preserving Metadata</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter
from langchain.text_splitter import RecursiveCharacterTextSplitter

converter = DocumentConverter()
result = converter.convert("document.pdf")

# Extract metadata
metadata = {
    "title": result.document.export_meta().get("title", ""),
    "author": result.document.export_meta().get("author", ""),
    "source": "document.pdf"
}

# Chunk with metadata
text = result.document.export_to_text()
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,
    chunk_overlap=50
)

chunks = text_splitter.create_documents(
    [text],
    metadatas=[metadata] * len(text_splitter.split_text(text))
)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_integration_with_llama_stack"><a class="anchor" href="#_integration_with_llama_stack"></a>Integration with Llama Stack</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_preparing_documents_for_ingestion"><a class="anchor" href="#_preparing_documents_for_ingestion"></a>Preparing Documents for Ingestion</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from docling import DocumentConverter
from langchain.text_splitter import RecursiveCharacterTextSplitter
import json

# Process document
converter = DocumentConverter()
result = converter.convert("document.pdf")
text = result.document.export_to_text()
metadata = result.document.export_meta()

# Chunk document
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,
    chunk_overlap=50
)
chunks = text_splitter.split_text(text)

# Prepare for Llama Stack ingestion
documents = []
for i, chunk in enumerate(chunks):
    documents.append({
        "id": f"doc1_chunk{i}",
        "text": chunk,
        "metadata": {
            "title": metadata.get("title", ""),
            "source": "document.pdf",
            "chunk_index": i
        }
    })

# Save for ingestion
with open("docling-output.json", "w") as f:
    json.dump({"documents": documents}, f)</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ingesting_to_llama_stack"><a class="anchor" href="#_ingesting_to_llama_stack"></a>Ingesting to Llama Stack</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Ingest processed documents to Llama Stack
curl -X POST $LLAMA_STACK_URL/ingest \
  -H "Content-Type: application/json" \
  -d @docling-output.json</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kubernetes_job_for_document_processing"><a class="anchor" href="#_kubernetes_job_for_document_processing"></a>Kubernetes Job for Document Processing</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_docling_job_configuration"><a class="anchor" href="#_docling_job_configuration"></a>Docling Job Configuration</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: batch/v1
kind: Job
metadata:
  name: docling-processing
  namespace: lean-rag-accelerator
spec:
  template:
    spec:
      containers:
      - name: docling
        image: python:3.11-slim
        command: ["/bin/bash", "-c"]
        args:
          - |
            pip install docling langchain
            python process_documents.py
        volumeMounts:
        - name: input-docs
          mountPath: /input
        - name: output-docs
          mountPath: /output
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
      volumes:
      - name: input-docs
        persistentVolumeClaim:
          claimName: input-documents-pvc
      - name: output-docs
        persistentVolumeClaim:
          claimName: processed-documents-pvc
      restartPolicy: Never
  backoffLimit: 3</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_best_practices"><a class="anchor" href="#_best_practices"></a>Best Practices</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_document_processing"><a class="anchor" href="#_document_processing"></a>Document Processing</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Use OCR for Scanned Documents</strong>: Enable OCR for PDFs with images</p>
</li>
<li>
<p><strong>Extract Tables</strong>: Preserve table structure for better context</p>
</li>
<li>
<p><strong>Preserve Metadata</strong>: Maintain document metadata for filtering</p>
</li>
<li>
<p><strong>Handle Errors</strong>: Implement error handling for corrupted documents</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_chunking_strategy"><a class="anchor" href="#_chunking_strategy"></a>Chunking Strategy</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Chunk Size</strong>: 512 tokens is a good starting point</p>
</li>
<li>
<p><strong>Overlap</strong>: 50 tokens overlap helps maintain context</p>
</li>
<li>
<p><strong>Semantic Chunking</strong>: Use semantic chunking for better retrieval</p>
</li>
<li>
<p><strong>Metadata</strong>: Include source, title, chunk index in metadata</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_performance"><a class="anchor" href="#_performance"></a>Performance</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Batch Processing</strong>: Process multiple documents in parallel</p>
</li>
<li>
<p><strong>Caching</strong>: Cache processed documents to avoid reprocessing</p>
</li>
<li>
<p><strong>Resource Allocation</strong>: Allocate sufficient memory for large documents</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_troubleshooting"><a class="anchor" href="#_troubleshooting"></a>Troubleshooting</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_ocr_issues"><a class="anchor" href="#_ocr_issues"></a>OCR Issues</h3>
<div class="paragraph">
<p><strong>Problem</strong>: Poor OCR quality</p>
</div>
<div class="paragraph">
<p><strong>Solutions:</strong>
- Ensure Tesseract is properly installed
- Use higher resolution source documents
- Adjust OCR language settings
- Pre-process images (contrast, noise reduction)</p>
</div>
</div>
<div class="sect2">
<h3 id="_memory_issues"><a class="anchor" href="#_memory_issues"></a>Memory Issues</h3>
<div class="paragraph">
<p><strong>Problem</strong>: Out of memory when processing large documents</p>
</div>
<div class="paragraph">
<p><strong>Solutions:</strong>
- Process documents in smaller batches
- Increase container memory limits
- Use streaming processing for very large documents</p>
</div>
</div>
<div class="sect2">
<h3 id="_format_issues"><a class="anchor" href="#_format_issues"></a>Format Issues</h3>
<div class="paragraph">
<p><strong>Problem</strong>: Unsupported document format</p>
</div>
<div class="paragraph">
<p><strong>Solutions:</strong>
- Convert documents to PDF first
- Check Docling version supports the format
- Use alternative processing tools for unsupported formats</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_key_takeaways"><a class="anchor" href="#_key_takeaways"></a>Key Takeaways</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Docling is a Python library for enterprise document processing</p>
</li>
<li>
<p>Supports PDF, images, audio with OCR capabilities</p>
</li>
<li>
<p>Outputs structured formats ready for RAG ingestion</p>
</li>
<li>
<p>Integrates with Llama Stack for document ingestion</p>
</li>
<li>
<p>Chunking is required after processing for RAG systems</p>
</li>
<li>
<p>Preserve metadata for better retrieval and filtering</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_next_steps"><a class="anchor" href="#_next_steps"></a>Next Steps</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Learn about orchestrating RAG workflows with Llama Stack API</p>
</li>
<li>
<p>Explore vector database integration options</p>
</li>
<li>
<p>Understand RAG evaluation with RAGAS</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>Documentation Gaps</strong>: This section would benefit from:
- Complete Docling API reference
- Advanced configuration examples
- Performance optimization guide
- Integration patterns with various RAG systems
- Real-world document processing examples</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="module-4-standardized-rag-implementation.html">Module 4: Standardized RAG Implementation</a></span>
  <span class="next"><a href="orchestrating-rag-workflows-using-the-llama-stack-api-for-standardized-response-generation-and-vector-io.html">Orchestrating RAG Workflows with the Llama Stack API</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
