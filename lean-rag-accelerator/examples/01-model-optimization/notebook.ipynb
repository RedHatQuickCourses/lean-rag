{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Compressor - Model Quantization\n",
        "\n",
        "This notebook demonstrates how to use LLM Compressor to quantize the Llama 3.1 8B model using SmoothQuant or GPTQ methods.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The Lean RAG Accelerator uses model quantization to:\n",
        "- Reduce memory footprint by 50-75%\n",
        "- Enable 2x to 4x higher throughput\n",
        "- Maintain >95% accuracy retention\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Access to LLM Compressor\n",
        "- Llama 3.1 8B model (or compatible model)\n",
        "- Calibration dataset\n",
        "- GPU with sufficient memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from llm_compressor import QuantizationRecipe, SmoothQuantModifier, GPTQModifier\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
        "MODEL_PATH = \"/mnt/models/llama-3.1-8b\"  # Update with your model path\n",
        "\n",
        "# Quantization configuration\n",
        "QUANTIZATION_METHOD = \"smoothquant\"  # Options: \"smoothquant\", \"gptq\"\n",
        "TARGET_PRECISION = \"int8\"  # Options: \"int8\" (smoothquant), \"int4\" (gptq)\n",
        "\n",
        "# Output configuration\n",
        "OUTPUT_PATH = \"/mnt/models/llama-3.1-8b-quantized\"  # Update with output path\n",
        "OUTPUT_FORMAT = \"onnx\"  # Options: \"onnx\", \"safetensors\", \"pytorch\"\n",
        "\n",
        "# Calibration dataset\n",
        "CALIBRATION_DATASET = \"/mnt/data/calibration\"  # Update with calibration dataset path\n",
        "NUM_CALIBRATION_SAMPLES = 512\n",
        "BATCH_SIZE = 8\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
